# ğŸ“– RAG-Based Chatbot for Uber Eats Knowledge Base

A Retrieval-Augmented Generation (RAG) chatbot designed to answer customer and partner queries about Uber Eats using an internal knowledge base. The system combines **document embeddings**, **FAISS vector search**, and **LLM inference via Ollama**, all wrapped in an interactive **Streamlit** interface.

---

## ğŸš€ Features

* ğŸ” **Document Retrieval** with FAISS vector database
* ğŸ§  **Sentence Embeddings** using `SentenceTransformers`
* ğŸ’¬ **LLM-powered responses** via Ollama (`llama3`, `mistral`, etc.)
* ğŸ“‘ Structured knowledge base built from Uber Eats Help Center articles
* ğŸŒ Streamlit web app with an easy-to-use interface
* âš¡ Configurable evaluation pipeline for testing multiple models

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ scripts/               # Data preprocessing & indexing scripts
â”‚   â”œâ”€â”€ normalize.py
â”‚   â”œâ”€â”€ build_index.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Original HTML/Markdown articles
â”‚   â”œâ”€â”€ clean/             # Cleaned/normalized Markdown
â”‚   â””â”€â”€ index/             # FAISS index + metadata
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/RAG-Based-Chatbot.git
cd RAG-Based-Chatbot
```

### 2. Create virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Pull Ollama models

```bash
ollama pull llama3
ollama pull mistral
```

---

## â–¶ï¸ Usage

### Run the Streamlit app

```bash
streamlit run app.py
```

### Example query

> *â€œWhat is Uber Eatsâ€™ cancellation policy?â€*
> The chatbot will retrieve relevant sections and generate a context-aware response.

---

## ğŸ§ª Evaluation

To benchmark retrieval and model accuracy:

```bash
python scripts/evaluate.py
```

Metrics include **accuracy, precision, recall, F1 score**, and qualitative comparison across models.

---

## ğŸ”‘ Environment Variables

Configure secrets (e.g., Ollama host, API keys) in `.streamlit/secrets.toml`:

```toml
OLLAMA_HOST="http://localhost:11434"
OLLAMA_AUTH="Basic <your-encoded-credentials>"
```

---

## ğŸ“Š Roadmap

* [ ] Deploy via Streamlit Cloud
* [ ] Add support for more LLMs (Gemma, GPT-4o, etc.)
* [ ] Expand knowledge base with merchant/courier policies
* [ ] Fine-tune retrieval pipeline

---

## ğŸ¤ Contributing

Pull requests are welcome! Please open an issue first to discuss major changes.
Ensure that all scripts follow PEP8 and include docstrings.

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see [LICENSE](LICENSE) for details.

---

âš¡ **Author:** [Your Name](https://github.com/<your-username>)
ğŸ’¬ Feel free to open an issue for questions or suggestions!

---

Do you want me to also create a **shorter professional version** (like a one-page summary README) for recruiters/hackathon judges, or should we keep it detailed for developers?


Hereâ€™s a solid **README.md** draft tailored for your repo (RAG-Based Chatbot for Uber Eats). You can copy it directly or tweak details like repo name, your username, or screenshots.

---

# ğŸ“– RAG-Based Chatbot for Uber Eats Knowledge Base

A **Retrieval-Augmented Generation (RAG)** chatbot that answers Uber Eats customer and partner queries using a structured knowledge base. It combines **document embeddings**, **FAISS vector search**, and **LLM inference via Ollama**, wrapped in a simple **Streamlit UI**.

---

## ğŸš€ Features

* ğŸ” Retrieve knowledge base articles with FAISS
* ğŸ§  Generate semantic embeddings with `SentenceTransformers`
* ğŸ’¬ Context-aware answers using Ollama models (`llama3`, `mistral`, etc.)
* ğŸ“‘ Knowledge base built from Uber Eats Help Center articles
* ğŸŒ Streamlit-powered interactive app
* âš¡ Evaluation pipeline for multiple models and metrics

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ normalize.py        # Data cleaning
â”‚   â”œâ”€â”€ build_index.py      # FAISS index creation
â”‚   â””â”€â”€ evaluate.py         # Model evaluation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw HTML/Markdown
â”‚   â”œâ”€â”€ clean/              # Normalized Markdown
â”‚   â””â”€â”€ index/              # FAISS index + metadata
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

```bash
# 1. Clone the repo
git clone https://github.com/<your-username>/RAG-Based-Chatbot.git
cd RAG-Based-Chatbot

# 2. Create virtual environment
python3 -m venv .venv
source .venv/bin/activate    # On Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Pull Ollama models
ollama pull llama3
ollama pull mistral
```

---

## â–¶ï¸ Usage

### Run Streamlit app

```bash
streamlit run app.py
```

### Example query

> *â€œWhat is Uber Eatsâ€™ cancellation policy?â€*
> The chatbot retrieves policy docs and generates a contextual answer.

---

## ğŸ§ª Evaluation

Run benchmark tests across models:

```bash
python scripts/evaluate.py
```

Metrics: **accuracy, precision, recall, F1**.

---

## ğŸ”‘ Environment Variables

Add to `.streamlit/secrets.toml`:

```toml
OLLAMA_HOST="http://localhost:11434"
OLLAMA_AUTH="Basic <your-encoded-credentials>"
```

---

## ğŸ“Š Roadmap

* [ ] Deploy on Streamlit Cloud
* [ ] Support for GPT-4o, Gemma, etc.
* [ ] Expand KB with merchant & courier docs
* [ ] Fine-tune retrieval pipeline

---

## ğŸ¤ Contributing

PRs welcome! Please open an issue before major changes.
Follow PEP8 + add docstrings.

---

## ğŸ“œ License

---

âš¡ **Author:** [Hihsikesh Phukan](https://github.com/s4031214)

