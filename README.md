# ğŸ“– RAG-Based Chatbot for Uber Eats Knowledge Base

A **Retrieval-Augmented Generation (RAG)** chatbot that answers Uber Eats customer and partner queries using a structured knowledge base. It combines **document embeddings**, **FAISS vector search**, and **LLM inference via Ollama**, wrapped in a simple **Streamlit UI**.

---

## ğŸš€ Features

* ğŸ” Retrieve knowledge base articles with FAISS
* ğŸ§  Generate semantic embeddings with `SentenceTransformers`
* ğŸ’¬ Context-aware answers using Ollama models (`llama3`, `mistral`, etc.)
* ğŸ“‘ Knowledge base built from Uber Eats Help Center articles
* ğŸŒ Streamlit-powered interactive app
* âš¡ Evaluation pipeline for multiple models and metrics

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ normalize.py        # Data cleaning
â”‚   â”œâ”€â”€ build_index.py      # FAISS index creation
â”‚   â””â”€â”€ evaluate.py         # Model evaluation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw HTML/Markdown
â”‚   â”œâ”€â”€ clean/              # Normalized Markdown
â”‚   â””â”€â”€ index/              # FAISS index + metadata
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

```bash
# 1. Clone the repo
git clone https://github.com/<your-username>/RAG-Based-Chatbot.git
cd RAG-Based-Chatbot

# 2. Create virtual environment
python3 -m venv .venv
source .venv/bin/activate    # On Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Pull Ollama models
ollama pull llama3
ollama pull mistral
```

---

## â–¶ï¸ Usage

### Run Streamlit app

```bash
streamlit run app.py
```

### Example query

> *â€œWhat is Uber Eatsâ€™ cancellation policy?â€*
> The chatbot retrieves policy docs and generates a contextual answer.

---

## ğŸ§ª Evaluation

Run benchmark tests across models:

```bash
python scripts/evaluate.py
```

Metrics: **accuracy, precision, recall, F1**.

---

## ğŸ”‘ Environment Variables

Add to `.streamlit/secrets.toml`:

```toml
OLLAMA_HOST="http://localhost:11434"
OLLAMA_AUTH="Basic <your-encoded-credentials>"
```

---

## ğŸ“Š Roadmap

* [ ] Deploy on Streamlit Cloud
* [ ] Support for GPT-4o, Gemma, etc.
* [ ] Expand KB with merchant & courier docs
* [ ] Fine-tune retrieval pipeline

---

## ğŸ¤ Contributing

PRs welcome! Please open an issue before major changes.
Follow PEP8 + add docstrings.

---

âš¡ **Author:** [Hihsikesh Phukan](https://github.com/s4031214)


